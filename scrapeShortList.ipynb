{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1c6a06-d423-42c8-89c2-07361f3a6cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import json\n",
    "from haralyzer import HarParser, HarPage\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from datetime import date\n",
    "import calendar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc2a655-a4a4-4a63-b732-a9128677f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address = '333 E Colorado Ave, Colorado Springs, CO 80903'\n",
    "# address_den = '115 W 10th Ave, Denver, CO 80204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e079b87a-3e61-48ed-ac90-f54ae20b687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeTrails(address):\n",
    "\n",
    "    curr_date = date.today()\n",
    "    today = str(calendar.day_name[curr_date.weekday()])\n",
    "    doys = {'Sunday': 0, 'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6}\n",
    "    \n",
    "    \n",
    "    url = \"https://9ioacg5nhe-dsn.algolia.net/1/indexes/alltrails_index3/query?x-algolia-agent=Algolia%20for%20JavaScript%20(4.8.6)%3B%20Browser\"\n",
    "\n",
    "    headers = CaseInsensitiveDict()\n",
    "    headers[\"Content-Type\"] = \"application/json\"\n",
    "    headers[\"Accept\"] = \"application/json\"\n",
    "    headers[\"Accept-Language\"] = \"en-US,en;q=0.9\"\n",
    "    headers[\"Accept-Encoding\"] = \"gzip, deflate, br\"\n",
    "    headers[\"Host\"] = \"9ioacg5nhe-dsn.algolia.net\"\n",
    "    headers[\"Origin\"] = \"https://www.alltrails.com\"\n",
    "    headers[\"User-Agent\"] = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15\"\n",
    "    headers[\"Connection\"] = \"keep-alive\"\n",
    "    headers[\"Referer\"] = \"https://www.alltrails.com/\"\n",
    "    headers[\"Content-Length\"] = \"2686\"\n",
    "    headers[\"x-algolia-application-id\"] = \"9IOACG5NHE\"\n",
    "    headers[\"x-algolia-api-key\"] = \"63a3cf94e0042b9c67abf0892fc1d223\"\n",
    "\n",
    "    data = '{\"query\":\"\",\"hitsPerPage\":1000,\"analyticsTags\":[\"auth:pro\",\"platform:web\",\"origin:explore\",\"actor:user\",\"lang:en\",\"hastext:false\"],\"attributesToRetrieve\":[\"ID\",\"_geoloc\",\"activities\",\"area_id\",\"area_name\",\"area_slug\",\"avg_rating\",\"city_id\",\"city_name\",\"country_id\",\"country_name\",\"created_at\",\"difficulty_rating\",\"duration_minutes\",\"duration_minutes_cycling\",\"duration_minutes_hiking\",\"duration_minutes_mountain_biking\",\"duration_minutes_trail_running\",\"elevation_gain\",\"filters\",\"has_profile_photo\",\"is_closed\",\"is_private_property\",\"length\",\"name\",\"num_photos\",\"num_reviews\",\"photo_count\",\"popularity\",\"profile_photo_data\",\"route_type\",\"slug\",\"state_id\",\"state_name\",\"type\",\"units\",\"user\",\"verified_map_id\",\"visitor_usage\",\"area_name_en\",\"city_name_en\",\"country_name_en\",\"state_name_en\",\"name_en\"],\"attributesToHighlight\":[],\"filters\":\"((length>=0)) AND ((elevation_gain>=0)) AND (objectID:trail-10344041 OR objectID:trail-10002885 OR objectID:trail-10260451 OR objectID:trail-10351821 OR objectID:trail-10351817 OR objectID:trail-10294852 OR objectID:trail-10017018 OR objectID:trail-10035463 OR objectID:trail-10005393 OR objectID:trail-10031135 OR objectID:trail-10294792 OR objectID:trail-10239233 OR objectID:trail-10043013 OR objectID:trail-10028431 OR objectID:trail-10035470 OR objectID:trail-10009934 OR objectID:trail-10279945 OR objectID:trail-10235969 OR objectID:trail-10031144 OR objectID:trail-10280978 OR objectID:trail-10030644 OR objectID:trail-10016671 OR objectID:trail-10018317 OR objectID:trail-10111944 OR objectID:trail-10001851 OR objectID:trail-10340507 OR objectID:trail-10253874 OR objectID:trail-10273673 OR objectID:trail-10239674 OR objectID:trail-10299934 OR objectID:trail-10259768 OR objectID:trail-10010211 OR objectID:trail-10551515 OR objectID:trail-10026684 OR objectID:trail-10015640 OR objectID:trail-10017023 OR objectID:trail-10026711 OR objectID:trail-10041185 OR objectID:trail-10235681 OR objectID:trail-10111237 OR objectID:trail-10241649 OR objectID:trail-10258958 OR objectID:trail-10035010 OR objectID:trail-10277791 OR objectID:trail-10253281 OR objectID:trail-10295745 OR objectID:trail-10009207 OR objectID:trail-10307880 OR objectID:trail-10003461 OR objectID:trail-10035011 OR objectID:trail-10014975 OR objectID:trail-10235688 OR objectID:trail-10005478 OR objectID:trail-10241141 OR objectID:trail-10037015 OR objectID:trail-10000215 OR objectID:trail-10008249 OR objectID:trail-10269270 OR objectID:trail-10034964 OR objectID:trail-10746249 OR objectID:trail-10256323 OR objectID:trail-10034993 OR objectID:trail-10263807 OR objectID:trail-10031833 OR objectID:trail-10289334)\",\"responseFields\":[\"hits\",\"hitsPerPage\",\"nbHits\"]}'\n",
    "\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "    print('Response Status: ' + str(resp.status_code))\n",
    "\n",
    "    hits = json.loads(resp.content)\n",
    "    #     with open('www.alltrails.com.har', 'r') as f:\n",
    "#         har_parser = HarParser(json.loads(f.read()))\n",
    "\n",
    "#     data = har_parser.har_data\n",
    "#     # print(data.keys())\n",
    "\n",
    "\n",
    "\n",
    "#     hits = json.loads(data['entries'][4]['response']['content']['text'])\n",
    "\n",
    "\n",
    "    hikes = pd.DataFrame.from_dict(hits['hits'])\n",
    "\n",
    "    # print(hikes)\n",
    "\n",
    "    # for hit in hits['hits']:\n",
    "    #     print(hit['name'])\n",
    "\n",
    "    # print(hit.keys())\n",
    "\n",
    "    hikes['duration_hours'] = hikes['duration_minutes']/60\n",
    "    hikes['distance_miles'] = hikes['length']*.000621371\n",
    "    \n",
    "    #get hike url list\n",
    "    hike_url = list('https://www.alltrails.com/'+hikes['slug'])\n",
    "    hikes['hike_url'] = pd.DataFrame(hike_url)\n",
    "\n",
    "    # hike_sample = hike_url[0:4]\n",
    "\n",
    "    hike_dict = dict()\n",
    "    weather = dict()\n",
    "\n",
    "    # print(hike_url)\n",
    "\n",
    "    driver = uc.Chrome()\n",
    "\n",
    "    driver.get(hike_url[0])\n",
    "    \n",
    "    import time\n",
    "\n",
    "    i = 20\n",
    "    while i > -1:\n",
    "        print('Solve Captcha in:', i, 'seconds', end='\\r')\n",
    "        time.sleep(1)\n",
    "        i -= 1\n",
    "    \n",
    "    #solve captcha once\n",
    "\n",
    "    #get metadata for each hike\n",
    "    \n",
    "    for hike in hike_url:\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        while attempts < 5 and not success:\n",
    "            try:\n",
    "                driver.get(hike)\n",
    "                hike_soup = BeautifulSoup(driver.page_source)\n",
    "                header = hike_soup.find('div', id='content')\n",
    "                metadata = header.findChild('div')['data-react-props']\n",
    "                metadata = json.loads(metadata)\n",
    "\n",
    "\n",
    "                name = metadata['trail']['name']\n",
    "                features = metadata['trailTags']['whatToSeeAndObstacles']\n",
    "                last_review_date = metadata['reviews']['trail_reviews'][0]['date']\n",
    "                last_review = metadata['reviews']['trail_reviews'][0]['comment']\n",
    "                if metadata['weatherConditionsProps']['weatherForecast'] != None:\n",
    "                    if doys[today] == 1:\n",
    "                        weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                        weather_nar_sun = 'n/a'\n",
    "                        clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                        clouds_sun = 'n/a'\n",
    "                        rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                        rain_sun = 'n/a'\n",
    "                        moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                        moon_sun = 'n/a'\n",
    "\n",
    "                    #weather_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['dow']\n",
    "                    # weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                    # weather_nar_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['narrative']\n",
    "                    # clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                    # clouds_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['clds']\n",
    "                    # rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                    # rain_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['pop']\n",
    "                    # moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                    # moon_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['lunar_phase']\n",
    "                    \n",
    "                    \n",
    "                    else:\n",
    "                        weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                        weather_nar_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['narrative']\n",
    "                        clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                        clouds_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['clds']\n",
    "                        rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                        rain_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['pop']\n",
    "                        moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                        moon_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['lunar_phase']\n",
    "\n",
    "                        #weather_nar_sat = weather_nar_sat + ' clouds: '+ str(clouds_sat)+ '%'\n",
    "                    #weather_nar_sun = weather_nar_sun + ' clouds: '+ str(clouds_sun)+ '%'\n",
    "\n",
    "                else:\n",
    "                    #weather_day = 'n/a'\n",
    "                    weather_nar_sat = 'n/a'\n",
    "                    weather_nar_sun = 'n/a'\n",
    "                    clouds_sat = 'n/a'\n",
    "                    clouds_sun = 'n/a'\n",
    "                    rain_sat = 'n/a'\n",
    "                    rain_sun = 'n/a'\n",
    "                    moon_sat = 'n/a'\n",
    "                    moon_sun = 'n/a'\n",
    "\n",
    "                    # weather_clouds = 'n/a'\n",
    "\n",
    "                # weather[weather_day] = {'summary': weather_nar, 'clouds':weather_clouds}\n",
    "                hike_info = {'features':features, 'last hiked': last_review_date, 'last review': last_review, 'saturday_weather': weather_nar_sat,'sunday_weather': weather_nar_sun, 'clouds_sat':clouds_sat,'clouds_sun': clouds_sun,'rain_sat':rain_sat,'rain_sun':rain_sun,'moon_phase_sat':moon_sat,'moon_phase_sun': moon_sun}\n",
    "                hike_dict[name] = hike_info\n",
    "\n",
    "                print('Processing:', name)\n",
    "                # print(features)\n",
    "                # print(hike_dict[name])\n",
    "                success = True\n",
    "            except:\n",
    "                attempts += 1\n",
    "                if attempts == 5:\n",
    "                    pass\n",
    "\n",
    "    # print(hike_dict)\n",
    "\n",
    "    # driver.get('https://www.alltrails.com/trail/us/colorado/wheeler-lake')\n",
    "    # test_hike = BeautifulSoup(driver.page_source)\n",
    "    # test_header = test_hike.find('div', id='content')\n",
    "    # test_metadata = test_header.findChild('div')['data-react-props']\n",
    "    # test_metadata = json.loads(test_metadata)\n",
    "    # test_name = metadata['trail']['name']\n",
    "    # test_features = metadata['trailTags']['whatToSeeAndObstacles']\n",
    "    # test_last_review_date = metadata['reviews']['trail_reviews'][0]['date']\n",
    "    # test_last_review = metadata['reviews']['trail_reviews'][0]['comment']\n",
    "    # test_metadata['weatherConditionsProps']['weatherForecast']['forecasts'][2]['lunar_phase']                                      \n",
    "\n",
    "    # print(test_hike)\n",
    "\n",
    "    metadata_df = pd.DataFrame.from_dict(hike_dict)\n",
    "    metadata_df = pd.DataFrame.transpose(metadata_df)\n",
    "    metadata_df.reset_index(inplace=True)\n",
    "\n",
    "    # print(metadata_df)\n",
    "\n",
    "    #get driving times\n",
    "    maps_url = []\n",
    "    n = 0\n",
    "    for hike in hikes._geoloc:\n",
    "        maps_url = maps_url + ['https://www.google.com/maps/dir/'+ address.replace(' ','+') + '/'  + str(hikes._geoloc[n]['lat']) + ',' + str(hikes._geoloc[n]['lng'])]\n",
    "        n = n+1\n",
    "\n",
    "    #get driving times from denver\n",
    "    # maps_url_den = []\n",
    "    # n = 0\n",
    "    # for hike in hikes._geoloc:\n",
    "    #     maps_url_den = maps_url_den + ['https://www.google.com/maps/dir/'+ address_den.replace(' ','+') + '/' + str(hikes._geoloc[n]['lat']) + ',' + str(hikes._geoloc[n]['lng'])]\n",
    "    #     n = n+1\n",
    "\n",
    "    # print(maps_url_den)\n",
    "\n",
    "    # maps_url\n",
    "\n",
    "    browser = webdriver.Chrome()\n",
    "\n",
    "    times = []\n",
    "    print('Getting driving times:')\n",
    "    j = 0\n",
    "    for dir in maps_url:\n",
    "        browser.get(dir)\n",
    "        maps = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "        dom = etree.HTML(str(maps))\n",
    "        if len(dom.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]'))>0:\n",
    "            times = times + [dom.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]')[0].text]\n",
    "\n",
    "        else: \n",
    "            times = times + ['n/a']\n",
    "        j += 1\n",
    "        print(str((round(j/len(maps_url) * 100, 1))) + ' % Complete')\n",
    "        # print(times)\n",
    "#     if add_den_address == 1:\n",
    "#         times_den = []\n",
    "    \n",
    "#         for dir in maps_url_den:\n",
    "#             browser.get(dir)\n",
    "#             maps_den = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "#             dom_den = etree.HTML(str(maps_den))\n",
    "#             if len(dom_den.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]'))>0:\n",
    "#                 times_den = times_den + [dom_den.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]')[0].text]\n",
    "\n",
    "#             else: \n",
    "#                 times_den = times_den + ['n/a']\n",
    "#             # print(times_den)\n",
    "#     else:\n",
    "#         pass\n",
    "    # hike_times = []\n",
    "\n",
    "    hike_times = pd.DataFrame()\n",
    "\n",
    "    hike_times['names'] = hikes.name\n",
    "    hike_times['driving_time_from_home'] = times\n",
    "\n",
    "    # print(hike_times)\n",
    "\n",
    "    total = []\n",
    "    for time in hike_times.driving_time_from_home:\n",
    "        if time != 'n/a':\n",
    "            time = time.split(' ')\n",
    "\n",
    "            try:\n",
    "                hr = int(time[0])\n",
    "                mins = int(time[2])\n",
    "                total = total + [hr*60 + mins]\n",
    "            except(IndexError):\n",
    "                hr = int(time[0])\n",
    "                mins = 0\n",
    "                total = total + [hr*60 + mins]\n",
    "        else:\n",
    "            total = total + [999]\n",
    "        #print(total)\n",
    "\n",
    "    hike_times['time_mins'] = total\n",
    "\n",
    "    hike_times = hike_times.sort_values('time_mins')\n",
    "\n",
    "    # print(hike_times)\n",
    "\n",
    "#     hike_times_den = []\n",
    "\n",
    "#     hike_times_den = pd.DataFrame()\n",
    "\n",
    "#     hike_times_den['names'] = hikes.name\n",
    "#     hike_times_den['driving_time_from_denver'] = times_den\n",
    "\n",
    "    # print(hike_times_den)\n",
    "#     if add_den_address == 1:\n",
    "#         total_den = []\n",
    "#         for time in hike_times_den.driving_time_from_denver:\n",
    "#             if time != 'n/a':\n",
    "#                 time = time.split(' ')\n",
    "\n",
    "#                 try:\n",
    "#                     hr = int(time[0])\n",
    "#                     mins = int(time[2])\n",
    "#                     total_den = total_den + [hr*60 + mins]\n",
    "#                 except(IndexError):\n",
    "#                     hr = int(time[0])\n",
    "#                     mins = 0\n",
    "#                     total_den = total_den + [hr*60 + mins]\n",
    "#             else:\n",
    "#                 total_den = total_den + [999]\n",
    "#             #print(total)\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "    # hike_times_den['time_mins'] = total_den\n",
    "\n",
    "    # hike_times_den = hike_times_den.sort_values('time_mins')\n",
    "\n",
    "    # print(hike_times_den)\n",
    "\n",
    "    full_hike_table = hike_times.merge(metadata_df, left_on = 'names', right_on = 'index')\n",
    "\n",
    "    # len(hike_times)\n",
    "\n",
    "    metadata_df.to_csv('all_trails_data_sample.csv')\n",
    "\n",
    "    # len(full_hike_table)\n",
    "\n",
    "    hike_times.to_csv('driving_times_from_home.csv')\n",
    "\n",
    "    # hike_times_den.to_csv('driving_times_from_Citzen.csv')\n",
    "\n",
    "    full_hike_table = full_hike_table.drop(columns = ['index','time_mins'])\n",
    "\n",
    "    full_hike_table.to_csv('hike_times_and_data.csv')\n",
    "\n",
    "    # full_hike_table = full_hike_table.merge(hike_times_den)\n",
    "\n",
    "    # full_hike_table = full_hike_table.drop(columns = ['time_mins'])\n",
    "\n",
    "    all_hike_data = full_hike_table.merge(hikes, left_on = 'names', right_on = 'name')\n",
    "\n",
    "\n",
    "    all_hike_data = all_hike_data.drop(columns = ['names','ID','state_id','length','slug','type', '_geoloc', 'route_type', 'visitor_usage','area_id','area_slug','city_id','country_id','verified_map_id','activities','profile_photo_data','has_profile_photo','num_photos','units','is_private_property','duration_minutes_trail_running','created_at','country_name','duration_minutes_mountain_biking','duration_minutes_hiking','duration_minutes','duration_minutes_cycling','duration_minutes_cycling','objectID'])\n",
    "\n",
    "    all_hike_data.index = all_hike_data.name\n",
    "\n",
    "    all_hike_data.insert(18, 'last review', all_hike_data.pop('last review'))\n",
    "\n",
    "    all_hike_data['elevation_gain'] = all_hike_data['elevation_gain'] * 3.28084\n",
    "\n",
    "    # all_hike_data = all_hike_data.drop(columns = ['name'])\n",
    "\n",
    "    # all_hike_data.insert(1, 'driving_time_from_denver', all_hike_data.pop('driving_time_from_denver'))\n",
    "    all_hike_data.insert(2, 'distance_miles', all_hike_data.pop('distance_miles'))\n",
    "    all_hike_data.insert(9, 'last hiked', all_hike_data.pop('last hiked'))\n",
    "    all_hike_data.insert(5, 'difficulty_rating', all_hike_data.pop('difficulty_rating'))\n",
    "    all_hike_data.insert(3, 'duration_hours', all_hike_data.pop('duration_hours'))\n",
    "    all_hike_data.insert(4, 'elevation_gain', all_hike_data.pop('elevation_gain'))\n",
    "    all_hike_data.insert(10, 'clouds_sat', all_hike_data.pop('clouds_sat'))\n",
    "    all_hike_data.insert(11, 'clouds_sun', all_hike_data.pop('clouds_sun'))\n",
    "\n",
    "\n",
    "    all_hike_data.elevation_gain = round(all_hike_data.elevation_gain,3)\n",
    "    all_hike_data.duration_hours = round(all_hike_data.duration_hours,3)\n",
    "    all_hike_data.distance_miles = round(all_hike_data.distance_miles,2)\n",
    "\n",
    "    all_hike_data = all_hike_data.rename(columns = {'elevation_gain':'elevation_gain_ft','rain_sun':'% chance rain sunday','rain_sat':'% chance rain saturday','clouds_sat':'% cloudy saturday','clouds_sun':'% cloudy sunday'})\n",
    "\n",
    "    all_hike_data['is_day_hike'] = np.where(all_hike_data['duration_hours']< 10 , True, False)\n",
    "\n",
    "    # all_hike_data['is_14er'] = np.where(all_hike_data['elevation_gain_ft']>=14000, True, False)\n",
    "\n",
    "    all_hike_data \n",
    "\n",
    "    all_hike_data.to_csv('complete_hike_data'+str(date.today())+'.csv')\n",
    "\n",
    "    return all_hike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d17e8-05f4-484e-a86c-cc4cf255804c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
