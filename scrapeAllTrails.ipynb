{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1c6a06-d423-42c8-89c2-07361f3a6cf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc\n",
    "import json\n",
    "from haralyzer import HarParser, HarPage\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from datetime import date\n",
    "import calendar\n",
    "import numpy as np\n",
    "%run getDataFrames.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dc2a655-a4a4-4a63-b732-a9128677f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# address = '333 E Colorado Ave, Colorado Springs, CO 80903'\n",
    "# address_den = '115 W 10th Ave, Denver, CO 80204'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e079b87a-3e61-48ed-ac90-f54ae20b687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allTrailsAny(address, trail_list, hike_day):\n",
    "\n",
    "    curr_date = date.today()\n",
    "    today = str(calendar.day_name[curr_date.weekday()])\n",
    "    doys = {'Sunday': 0, 'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6}\n",
    "    \n",
    "    if abs(doys[hike_day] - doys[today]) > 5:\n",
    "        print('Choose earlier hiking day. Weather data not available yet.')    \n",
    "        return\n",
    "    \n",
    "    trail_dict = {'all14ers': getall14ers ,'top14ers':gettop14ers, 'short_list':getshortlist, 'allCO':getallco}\n",
    "    hikes = trail_dict[trail_list]()\n",
    "\n",
    "    # print(hikes)\n",
    "\n",
    "    # for hit in hits['hits']:\n",
    "    #     print(hit['name'])\n",
    "\n",
    "    # print(hit.keys())\n",
    "\n",
    "    hikes['duration_hours'] = hikes['duration_minutes']/60\n",
    "    hikes['distance_miles'] = hikes['length']*.000621371\n",
    "    \n",
    "    #get hike url list\n",
    "    hike_url = list('https://www.alltrails.com/'+hikes['slug'])\n",
    "    hikes['hike_url'] = pd.DataFrame(hike_url)\n",
    "\n",
    "    # hike_sample = hike_url[0:4]\n",
    "\n",
    "    hike_dict = dict()\n",
    "    weather = dict()\n",
    "\n",
    "    # print(hike_url)\n",
    "\n",
    "    driver = uc.Chrome()\n",
    "\n",
    "    driver.get(hike_url[0])\n",
    "    \n",
    "    import time\n",
    "\n",
    "    i = 20\n",
    "    while i > -1:\n",
    "        print('Solve Captcha in:', i, 'seconds', end='\\r')\n",
    "        time.sleep(1)\n",
    "        i -= 1\n",
    "    \n",
    "    #solve captcha once\n",
    "\n",
    "    #get metadata for each hike\n",
    "    \n",
    "    for hike in hike_url:\n",
    "        attempts = 0\n",
    "        success = False\n",
    "        while attempts < 5 and not success:\n",
    "            try:\n",
    "                driver.get(hike)\n",
    "                hike_soup = BeautifulSoup(driver.page_source)\n",
    "                header = hike_soup.find('div', id='content')\n",
    "                metadata = header.findChild('div')['data-react-props']\n",
    "                metadata = json.loads(metadata)\n",
    "\n",
    "\n",
    "                name = metadata['trail']['name']\n",
    "                features = metadata['trailTags']['whatToSeeAndObstacles']\n",
    "                last_review_date = metadata['reviews']['trail_reviews'][0]['date']\n",
    "                last_review = metadata['reviews']['trail_reviews'][0]['comment']\n",
    "                if metadata['weatherConditionsProps']['weatherForecast'] != None:\n",
    "                    if doys[today] == 1:\n",
    "                        weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                        weather_nar_sun = 'n/a'\n",
    "                        clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                        clouds_sun = 'n/a'\n",
    "                        rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                        rain_sun = 'n/a'\n",
    "                        moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                        moon_sun = 'n/a'\n",
    "                        weather_nar_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['narrative']\n",
    "                        clouds_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['clds']\n",
    "                        rain_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['pop']\n",
    "\n",
    "                    #weather_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['dow']\n",
    "                    # weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                    # weather_nar_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['narrative']\n",
    "                    # clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                    # clouds_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['clds']\n",
    "                    # rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                    # rain_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['pop']\n",
    "                    # moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                    # moon_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['lunar_phase']\n",
    "                    \n",
    "                    \n",
    "                    else:\n",
    "                        weather_nar_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['narrative']\n",
    "                        weather_nar_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['narrative']\n",
    "                        clouds_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['clds']\n",
    "                        clouds_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['clds']\n",
    "                        rain_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['day']['pop']\n",
    "                        rain_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['day']['pop']\n",
    "                        moon_sat = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][6 - doys[today]]['lunar_phase']\n",
    "                        moon_sun = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][7 - doys[today]]['lunar_phase']\n",
    "                        weather_nar_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['narrative']\n",
    "                        clouds_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['clds']\n",
    "                        rain_hike_day = metadata['weatherConditionsProps']['weatherForecast']['forecasts'][abs(doys[hike_day]-doys[today])]['day']['pop']\n",
    "\n",
    "                        #weather_nar_sat = weather_nar_sat + ' clouds: '+ str(clouds_sat)+ '%'\n",
    "                    #weather_nar_sun = weather_nar_sun + ' clouds: '+ str(clouds_sun)+ '%'\n",
    "\n",
    "                else:\n",
    "                    #weather_day = 'n/a'\n",
    "                    weather_nar_sat = 'n/a'\n",
    "                    weather_nar_sun = 'n/a'\n",
    "                    clouds_sat = 'n/a'\n",
    "                    clouds_sun = 'n/a'\n",
    "                    rain_sat = 'n/a'\n",
    "                    rain_sun = 'n/a'\n",
    "                    moon_sat = 'n/a'\n",
    "                    moon_sun = 'n/a'\n",
    "                    weather_nar_hike_day = 'n/a'\n",
    "                    clouds_hike_day = 'n/a'\n",
    "                    rain_hike_day = 'n/a'\n",
    "\n",
    "                    # weather_clouds = 'n/a'\n",
    "\n",
    "                # weather[weather_day] = {'summary': weather_nar, 'clouds':weather_clouds}\n",
    "                hike_info = {'features':features, 'last hiked': last_review_date, 'last review': last_review, 'saturday_weather': weather_nar_sat,\\\n",
    "                             'sunday_weather': weather_nar_sun, 'clouds_sat':clouds_sat,'clouds_sun': clouds_sun,'rain_sat':rain_sat,\\\n",
    "                             'rain_sun':rain_sun,'moon_phase_sat':moon_sat,'moon_phase_sun': moon_sun,\\\n",
    "                            'clouds_hike_day': clouds_hike_day,'rain_hike_day':rain_hike_day,\\\n",
    "                             'hike_day_weather':weather_nar_hike_day}\n",
    "                hike_dict[name] = hike_info\n",
    "\n",
    "                print('Processing:', name)\n",
    "                # print(features)\n",
    "                # print(hike_dict[name])\n",
    "                success = True\n",
    "            except:\n",
    "                attempts += 1\n",
    "                if attempts == 5:\n",
    "                    pass\n",
    "\n",
    "    # print(hike_dict)\n",
    "\n",
    "    # driver.get('https://www.alltrails.com/trail/us/colorado/wheeler-lake')\n",
    "    # test_hike = BeautifulSoup(driver.page_source)\n",
    "    # test_header = test_hike.find('div', id='content')\n",
    "    # test_metadata = test_header.findChild('div')['data-react-props']\n",
    "    # test_metadata = json.loads(test_metadata)\n",
    "    # test_name = metadata['trail']['name']\n",
    "    # test_features = metadata['trailTags']['whatToSeeAndObstacles']\n",
    "    # test_last_review_date = metadata['reviews']['trail_reviews'][0]['date']\n",
    "    # test_last_review = metadata['reviews']['trail_reviews'][0]['comment']\n",
    "    # test_metadata['weatherConditionsProps']['weatherForecast']['forecasts'][2]['lunar_phase']                                      \n",
    "\n",
    "    # print(test_hike)\n",
    "\n",
    "    metadata_df = pd.DataFrame.from_dict(hike_dict)\n",
    "    metadata_df = pd.DataFrame.transpose(metadata_df)\n",
    "    metadata_df.reset_index(inplace=True)\n",
    "\n",
    "    # print(metadata_df)\n",
    "\n",
    "    #get driving times\n",
    "    maps_url = []\n",
    "    n = 0\n",
    "    for hike in hikes._geoloc:\n",
    "        maps_url = maps_url + ['https://www.google.com/maps/dir/'+ address.replace(' ','+') + '/'  + str(hikes._geoloc[n]['lat']) + ',' + str(hikes._geoloc[n]['lng'])]\n",
    "        n = n+1\n",
    "\n",
    "    #get driving times from denver\n",
    "    # maps_url_den = []\n",
    "    # n = 0\n",
    "    # for hike in hikes._geoloc:\n",
    "    #     maps_url_den = maps_url_den + ['https://www.google.com/maps/dir/'+ address_den.replace(' ','+') + '/' + str(hikes._geoloc[n]['lat']) + ',' + str(hikes._geoloc[n]['lng'])]\n",
    "    #     n = n+1\n",
    "\n",
    "    # print(maps_url_den)\n",
    "\n",
    "    # maps_url\n",
    "\n",
    "    browser = webdriver.Chrome()\n",
    "\n",
    "    times = []\n",
    "    print('Getting driving times:')\n",
    "    j = 0\n",
    "    for dir in maps_url:\n",
    "        browser.get(dir)\n",
    "        maps = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "        dom = etree.HTML(str(maps))\n",
    "        if len(dom.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]'))>0:\n",
    "            times = times + [dom.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]')[0].text]\n",
    "\n",
    "        else: \n",
    "            browser.get('https://www.google.com/maps/dir/'+ address.replace(' ','+') + '/'  + hikes.city_name[j]+',+CO')\n",
    "            maps = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "            dom = etree.HTML(str(maps))\n",
    "            times = times + [dom.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]')[0].text]\n",
    "\n",
    "            # times = times + ['n/a']\n",
    "        j += 1\n",
    "        print(str((round(j/len(maps_url) * 100, 1))) + ' % Complete')\n",
    "        # print(times)\n",
    "#     if add_den_address == 1:\n",
    "#         times_den = []\n",
    "    \n",
    "#         for dir in maps_url_den:\n",
    "#             browser.get(dir)\n",
    "#             maps_den = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "#             dom_den = etree.HTML(str(maps_den))\n",
    "#             if len(dom_den.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]'))>0:\n",
    "#                 times_den = times_den + [dom_den.xpath('//*[@id=\"section-directions-trip-0\"]/div[1]/div[1]/div[1]/div[1]/span[1]')[0].text]\n",
    "\n",
    "#             else: \n",
    "#                 times_den = times_den + ['n/a']\n",
    "#             # print(times_den)\n",
    "#     else:\n",
    "#         pass\n",
    "    # hike_times = []\n",
    "\n",
    "    hike_times = pd.DataFrame()\n",
    "\n",
    "    hike_times['names'] = hikes.name\n",
    "    hike_times['driving_time_from_home'] = times\n",
    "\n",
    "    # print(hike_times)\n",
    "\n",
    "    total = []\n",
    "    for time in hike_times.driving_time_from_home:\n",
    "        if time != 'n/a':\n",
    "            time = time.split(' ')\n",
    "\n",
    "            try:\n",
    "                hr = int(time[0])\n",
    "                mins = int(time[2])\n",
    "                total = total + [hr*60 + mins]\n",
    "            except(IndexError):\n",
    "                hr = int(time[0])\n",
    "                mins = 0\n",
    "                total = total + [hr*60 + mins]\n",
    "        else:\n",
    "            total = total + [999]\n",
    "        #print(total)\n",
    "\n",
    "    hike_times['time_mins'] = total\n",
    "\n",
    "    hike_times = hike_times.sort_values('time_mins')\n",
    "\n",
    "    # print(hike_times)\n",
    "\n",
    "#     hike_times_den = []\n",
    "\n",
    "#     hike_times_den = pd.DataFrame()\n",
    "\n",
    "#     hike_times_den['names'] = hikes.name\n",
    "#     hike_times_den['driving_time_from_denver'] = times_den\n",
    "\n",
    "    # print(hike_times_den)\n",
    "#     if add_den_address == 1:\n",
    "#         total_den = []\n",
    "#         for time in hike_times_den.driving_time_from_denver:\n",
    "#             if time != 'n/a':\n",
    "#                 time = time.split(' ')\n",
    "\n",
    "#                 try:\n",
    "#                     hr = int(time[0])\n",
    "#                     mins = int(time[2])\n",
    "#                     total_den = total_den + [hr*60 + mins]\n",
    "#                 except(IndexError):\n",
    "#                     hr = int(time[0])\n",
    "#                     mins = 0\n",
    "#                     total_den = total_den + [hr*60 + mins]\n",
    "#             else:\n",
    "#                 total_den = total_den + [999]\n",
    "#             #print(total)\n",
    "#     else:\n",
    "#         pass\n",
    "\n",
    "    # hike_times_den['time_mins'] = total_den\n",
    "\n",
    "    # hike_times_den = hike_times_den.sort_values('time_mins')\n",
    "\n",
    "    # print(hike_times_den)\n",
    "\n",
    "    full_hike_table = hike_times.merge(metadata_df, left_on = 'names', right_on = 'index')\n",
    "\n",
    "    # len(hike_times)\n",
    "\n",
    "    metadata_df.to_csv('all_trails_data_sample.csv')\n",
    "\n",
    "    # len(full_hike_table)\n",
    "\n",
    "    hike_times.to_csv('driving_times_from_home.csv')\n",
    "\n",
    "    # hike_times_den.to_csv('driving_times_from_Citzen.csv')\n",
    "\n",
    "    full_hike_table = full_hike_table.drop(columns = ['index','time_mins'])\n",
    "\n",
    "    full_hike_table.to_csv('hike_times_and_data.csv')\n",
    "\n",
    "    # full_hike_table = full_hike_table.merge(hike_times_den)\n",
    "\n",
    "    # full_hike_table = full_hike_table.drop(columns = ['time_mins'])\n",
    "\n",
    "    all_hike_data = full_hike_table.merge(hikes, left_on = 'names', right_on = 'name')\n",
    "\n",
    "\n",
    "    all_hike_data = all_hike_data.drop(columns = ['names','ID','state_id','length','slug','type', '_geoloc', 'route_type', 'visitor_usage','area_id','area_slug','city_id','country_id','verified_map_id','activities','profile_photo_data','has_profile_photo','num_photos','units','is_private_property','duration_minutes_trail_running','created_at','country_name','duration_minutes_mountain_biking','duration_minutes_hiking','duration_minutes','duration_minutes_cycling','duration_minutes_cycling','objectID'])\n",
    "\n",
    "    all_hike_data.index = all_hike_data.name\n",
    "\n",
    "    all_hike_data.insert(18, 'last review', all_hike_data.pop('last review'))\n",
    "\n",
    "    all_hike_data['elevation_gain'] = all_hike_data['elevation_gain'] * 3.28084\n",
    "    \n",
    "    if hike_day == 'Saturday' or hike_day == 'Sunday':\n",
    "        all_hike_data = all_hike_data.drop(columns = ['hike_day_weather', 'clouds_hike_day', 'rain_hike_day'])\n",
    "    else:\n",
    "        all_hike_data = all_hike_data.rename(columns = {'hike_day_weather':hike_day+'_weather', 'clouds_hike_day':'% cloudy '+hike_day, 'rain_hike_day':'% chance rain '+hike_day})\n",
    "\n",
    "    # all_hike_data = all_hike_data.drop(columns = ['name'])\n",
    "\n",
    "    # all_hike_data.insert(1, 'driving_time_from_denver', all_hike_data.pop('driving_time_from_denver'))\n",
    "    all_hike_data.insert(2, 'distance_miles', all_hike_data.pop('distance_miles'))\n",
    "    all_hike_data.insert(9, 'last hiked', all_hike_data.pop('last hiked'))\n",
    "    all_hike_data.insert(5, 'difficulty_rating', all_hike_data.pop('difficulty_rating'))\n",
    "    all_hike_data.insert(3, 'duration_hours', all_hike_data.pop('duration_hours'))\n",
    "    all_hike_data.insert(4, 'elevation_gain', all_hike_data.pop('elevation_gain'))\n",
    "    all_hike_data.insert(10, 'clouds_sat', all_hike_data.pop('clouds_sat'))\n",
    "    all_hike_data.insert(11, 'clouds_sun', all_hike_data.pop('clouds_sun'))\n",
    "    # all_hike_data.insert(12, '% cloudy ' + hike_day, all_hike_data.pop('% cloudy ' + hike_day))\n",
    "\n",
    "\n",
    "    all_hike_data.elevation_gain = round(all_hike_data.elevation_gain,3)\n",
    "    all_hike_data.duration_hours = round(all_hike_data.duration_hours,3)\n",
    "    all_hike_data.distance_miles = round(all_hike_data.distance_miles,2)\n",
    "\n",
    "    all_hike_data = all_hike_data.rename(columns = {'elevation_gain':'elevation_gain_ft','rain_sun':'% chance rain Sunday','rain_sat':'% chance rain Saturday','clouds_sat':'% cloudy Saturday','clouds_sun':'% cloudy Sunday'})\n",
    "\n",
    "    all_hike_data['is_day_hike'] = np.where(all_hike_data['duration_hours']< 10 , True, False)\n",
    "\n",
    "    # all_hike_data['is_14er'] = np.where(all_hike_data['elevation_gain_ft']>=14000, True, False)\n",
    "\n",
    "    all_hike_data \n",
    "\n",
    "    all_hike_data.to_csv('complete_hike_data'+str(date.today())+'.csv')\n",
    "\n",
    "    return all_hike_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d17e8-05f4-484e-a86c-cc4cf255804c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
